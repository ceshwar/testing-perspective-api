{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample_comments = pd.read_csv('sample-comments.csv', names = ['comments'], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello world! What is up?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOL, this is crazy. Are you stupid tho?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is disgusting!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  comments\n",
       "0                 Hello world! What is up?\n",
       "1  LOL, this is crazy. Are you stupid tho?\n",
       "2                     This is disgusting! "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Hello world! What is up?\n",
      "P(Toxicity) = 0.024962198\n",
      "1 : LOL, this is crazy. Are you stupid tho?\n",
      "P(Toxicity) = 0.9039304\n",
      "2 : This is disgusting! \n",
      "P(Toxicity) = 0.53198034\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient import discovery\n",
    "import pandas as pd\n",
    "\n",
    "sample_comments = pd.read_csv('sample-comments.csv', names = ['comments'], sep='\\t')\n",
    "API_KEY = pd.read_csv('api-key.txt', names = ['key'])['key'][0]\n",
    "\n",
    "# Generates API client object dynamically based on service name and version.\n",
    "service = discovery.build('commentanalyzer', 'v1alpha1', developerKey=API_KEY)\n",
    "\n",
    "count = 0\n",
    "toxicity_scores = []\n",
    "\n",
    "for comment in sample_comments['comments']:\n",
    "    print(str(count) + \" : \" + comment)\n",
    "    count += 1\n",
    "\n",
    "    analyze_request = {\n",
    "      'comment': { 'text': comment},\n",
    "    #  'comment': { 'text': 'friendly greetings from python'},\n",
    "      'requestedAttributes': {'TOXICITY': {}}\n",
    "    }\n",
    "\n",
    "    response = service.comments().analyze(body=analyze_request).execute()\n",
    "#     import json\n",
    "#     print(json.dumps(response, indent=2))\n",
    "    toxicity_score = response['attributeScores']['TOXICITY']['summaryScore']['value']\n",
    "\n",
    "    print(\"P(Toxicity) = \" + str(toxicity_score))\n",
    "    toxicity_scores.append(toxicity_score)\n",
    "\n",
    "sample_comments['toxicity'] = toxicity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello world! What is up?</td>\n",
       "      <td>0.024962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOL, this is crazy. Are you stupid tho?</td>\n",
       "      <td>0.903930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is disgusting!</td>\n",
       "      <td>0.531980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  comments  toxicity\n",
       "0                 Hello world! What is up?  0.024962\n",
       "1  LOL, this is crazy. Are you stupid tho?  0.903930\n",
       "2                     This is disgusting!   0.531980"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "lex = pd.read_csv('/Users/eshwar/Downloads/words_categories_dict.txt', sep = '\\t')\n",
    "\n",
    "delim = \" \"\n",
    "cat = \"ethnicity\"\n",
    "print(lex[lex.category == delim + cat].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro comments - toxicity scores from Perspective API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = pd.read_csv('/Users/eshwar/Desktop/research/repos/norm-network/final-cluster-agreements.csv')\n",
    "macro = tf[['comment', 'subreddit', 'total']]\n",
    "macro = macro.drop_duplicates(subset='comment', keep=\"last\")\n",
    "macro_limit = int(0.01 * macro.shape[0])  ###top 1 percentile - gives agreement > 85%\n",
    "macro_comments = macro.sort_values(by = ['total'], ascending=[False])[:macro_limit]\n",
    "macro_comments.to_csv('macro-comments.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "import pandas as pd\n",
    "\n",
    "# sample_comments = pd.read_csv('sample-comments.csv', names = ['comments'], sep='\\t')\n",
    "sample_comments = pd.read_csv('macro-comments.csv')\n",
    "\n",
    "API_KEY = pd.read_csv('api-key.txt', names = ['key'])['key'][0]\n",
    "\n",
    "# Generates API client object dynamically based on service name and version.\n",
    "service = discovery.build('commentanalyzer', 'v1alpha1', developerKey=API_KEY)\n",
    "\n",
    "count = 0\n",
    "toxicity_scores = []\n",
    "\n",
    "# for comment in sample_comments['comments']:\n",
    "for comment in sample_comments['comment']:\n",
    "    print(str(count) + \" : \" + comment)\n",
    "    count += 1\n",
    "\n",
    "    analyze_request = {\n",
    "      'comment': { 'text': comment},\n",
    "    #  'comment': { 'text': 'friendly greetings from python'},\n",
    "      'requestedAttributes': {'TOXICITY': {}}\n",
    "    }\n",
    "\n",
    "    response = service.comments().analyze(body=analyze_request).execute()\n",
    "#     import json\n",
    "#     print(json.dumps(response, indent=2))\n",
    "    toxicity_score = response['attributeScores']['TOXICITY']['summaryScore']['value']\n",
    "\n",
    "    print(\"P(Toxicity) = \" + str(toxicity_score))\n",
    "    toxicity_scores.append(toxicity_score)\n",
    "\n",
    "sample_comments['toxicity'] = toxicity_scores\n",
    "sample_comments.to_csv('macro-comments-toxicity.csv', index = False)\n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gantt chart - Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Creates a simple Gantt chart\n",
    "# Adapted from https://bitbucket.org/DBrent/phd/src/1d1c5444d2ba2ee3918e0dfd5e886eaeeee49eec/visualisation/plot_gantt.py\n",
    "# BHC 2014\n",
    "# \"\"\"\n",
    " \n",
    "# import datetime as dt\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.font_manager as font_manager\n",
    "# import matplotlib.dates\n",
    "# from matplotlib.dates import MONTHLY, DateFormatter, rrulewrapper, RRuleLocator\n",
    " \n",
    "# %matplotlib inline \n",
    "# from pylab import *\n",
    "\n",
    "# def create_date(month,year):\n",
    "#     \"\"\"Creates the date\"\"\"\n",
    "\n",
    "#     date = dt.datetime(int(year), int(month), 1)\n",
    "#     mdate = matplotlib.dates.date2num(date)\n",
    "\n",
    "#     return mdate\n",
    " \n",
    "# # Data\n",
    " \n",
    "# pos = arange(0.5,5.5,0.5)\n",
    " \n",
    "# ylabels = []\n",
    "# ylabels.append('Hardware Design & Review')\n",
    "# ylabels.append('Hardware Construction')\n",
    "# ylabels.append('Integrate and Test Laser Source')\n",
    "# ylabels.append('Objective #1')\n",
    "# ylabels.append('Objective #2')\n",
    "# ylabels.append('Present at ASMS')\n",
    "# ylabels.append('Present Data at Gordon Conference')\n",
    "# ylabels.append('Manuscripts and Final Report')\n",
    " \n",
    "# effort = []\n",
    "# effort.append([0.2, 1.0])\n",
    "# effort.append([0.2, 1.0])\n",
    "# effort.append([0.2, 1.0])\n",
    "# effort.append([0.3, 0.75])\n",
    "# effort.append([0.25, 0.75])\n",
    "# effort.append([0.3, 0.75])\n",
    "# effort.append([0.5, 0.5])\n",
    "# effort.append([0.7, 0.4])\n",
    " \n",
    "# customDates = []\n",
    "# customDates.append([create_date(5,2014),create_date(6,2014)])\n",
    "# customDates.append([create_date(6,2014),create_date(8,2014),create_date(8,2014)])\n",
    "# customDates.append([create_date(7,2014),create_date(9,2014),create_date(9,2014)])\n",
    "# customDates.append([create_date(10,2014),create_date(3,2015),create_date(3,2015)])\n",
    "# customDates.append([create_date(2,2015),create_date(6,2015),create_date(6,2015)])\n",
    "# customDates.append([create_date(5,2015),create_date(6,2015),create_date(6,2015)])\n",
    "# customDates.append([create_date(6,2015),create_date(7,2015),create_date(7,2015)])\n",
    "# customDates.append([create_date(4,2015),create_date(8,2015),create_date(8,2015)])\n",
    " \n",
    "# task_dates = {}\n",
    "# for i,task in enumerate(ylabels):\n",
    "#     task_dates[task] = customDates[i]\n",
    "#     # task_dates['Climatology'] = [create_date(5,2014),create_date(6,2014),create_date(10,2013)]\n",
    "#     # task_dates['Structure'] = [create_date(10,2013),create_date(3,2014),create_date(5,2014)]\n",
    "#     # task_dates['Impacts'] = [create_date(5,2014),create_date(12,2014),create_date(2,2015)]\n",
    "#     # task_dates['Thesis'] = [create_date(2,2015),create_date(5,2015)]\n",
    " \n",
    "# # Initialise plot\n",
    "# fig = plt.figure()\n",
    "# # ax = fig.add_axes([0.15,0.2,0.75,0.3]) #[left,bottom,width,height]\n",
    "# ax = fig.add_subplot(111)\n",
    " \n",
    "# # Plot the data\n",
    " \n",
    "# start_date,end_date = task_dates[ylabels[0]]\n",
    "# ax.barh(0.5, end_date - start_date, left=start_date, height=0.3, align='center', color='blue', alpha = 0.75)\n",
    "# ax.barh(0.45, (end_date - start_date)*effort[0][0], left=start_date, height=0.1, align='center', color='red', alpha = 0.75, label = \"PI Effort\")\n",
    "# ax.barh(0.55, (end_date - start_date)*effort[0][1], left=start_date, height=0.1, align='center', color='yellow', alpha = 0.75, label = \"Student Effort\")\n",
    "# for i in range(0,len(ylabels)-1):\n",
    "#     labels = ['Analysis','Reporting'] if i == 1 else [None,None]    \n",
    "#     start_date,mid_date,end_date = task_dates[ylabels[i+1]]\n",
    "#     piEffort, studentEffort = effort[i+1]\n",
    "#     ax.barh((i*0.5)+1.0, mid_date - start_date, left=start_date, height=0.3, align='center', color='blue', alpha = 0.75)\n",
    "#     ax.barh((i*0.5)+1.0-0.05, (mid_date - start_date)*piEffort, left=start_date, height=0.1, align='center', color='red', alpha = 0.75)\n",
    "#     ax.barh((i*0.5)+1.0+0.05, (mid_date - start_date)*studentEffort, left=start_date, height=0.1, align='center', color='yellow', alpha = 0.75)\n",
    "#     # ax.barh((i*0.5)+1.0, end_date - mid_date, left=mid_date, height=0.3, align='center',label=labels[1], color='yellow')\n",
    " \n",
    "# # Format the y-axis\n",
    " \n",
    "# locsy, labelsy = yticks(pos,ylabels)\n",
    "# plt.setp(labelsy, fontsize = 14)\n",
    " \n",
    "# # Format the x-axis\n",
    " \n",
    "# ax.axis('tight')\n",
    "# ax.set_ylim(ymin = -0.1, ymax = 4.5)\n",
    "# ax.grid(color = 'g', linestyle = ':')\n",
    " \n",
    "# ax.xaxis_date() #Tell matplotlib that these are dates...\n",
    " \n",
    "# rule = rrulewrapper(MONTHLY, interval=1)\n",
    "# loc = RRuleLocator(rule)\n",
    "# formatter = DateFormatter(\"%b '%y\")\n",
    " \n",
    "# ax.xaxis.set_major_locator(loc)\n",
    "# ax.xaxis.set_major_formatter(formatter)\n",
    "# labelsx = ax.get_xticklabels()\n",
    "# plt.setp(labelsx, rotation=30, fontsize=12)\n",
    "\n",
    "# # Format the legend\n",
    " \n",
    "# font = font_manager.FontProperties(size='small')\n",
    "# ax.legend(loc=1,prop=font)\n",
    " \n",
    "# # Finish up\n",
    "# ax.invert_yaxis()\n",
    "# fig.autofmt_xdate()\n",
    "# #plt.savefig('gantt.svg')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Reals!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly\n",
    "\n",
    "# plotly.tools.set_config_file(world_readable=False,\n",
    "#                              sharing='private')\n",
    "\n",
    "\n",
    "# plotly.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import plotly.plotly as py\n",
    "# import plotly.figure_factory as ff\n",
    "\n",
    "# df = [dict(Task=\"Write up proposal\", Start='2018-10-17', Finish='2018-11-15'),\n",
    "#       dict(Task=\"Prepare proposal PPT\", Start='2018-11-15', Finish='2018-11-30'),\n",
    "#       dict(Task=\"Russian Troll Detection\", Start='2018-10-03', Finish='2018-10-12')]\n",
    "\n",
    "# fig = ff.create_gantt(df)\n",
    "# py.iplot(fig, filename='gantt-simple-gantt-chart', world_readable=True)\n",
    "\n",
    "# # import plotly.plotly as py\n",
    "# # import plotly.figure_factory as ff\n",
    "\n",
    "# # df = [dict(Task=\"Job A\", Start='2009-01-01', Finish='2009-02-28'),\n",
    "# #       dict(Task=\"Job B\", Start='2009-03-05', Finish='2009-04-15'),\n",
    "# #       dict(Task=\"Job C\", Start='2009-02-20', Finish='2009-05-30')]\n",
    "\n",
    "# # fig = ff.create_gantt(df)\n",
    "# # py.iplot(fig, filename='gantt-simple-gantt-chart', world_readable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~maxpayneog/2.embed\" height=\"600px\" width=\"900px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference: https://plot.ly/python/gantt/\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "df = [\n",
    "         dict(Task=\"P1\", Start='2018-10-17', Finish='2018-11-15', Resource='P1: Write up proposal'),\n",
    "         dict(Task=\"P2\", Start='2018-11-15', Finish='2018-11-30', Resource='P2: Prep proposal PPT'),\n",
    "         dict(Task=\"P3\", Start='2018-12-07', Finish='2018-12-15', Resource='P3: Finish proposal'),\n",
    "         dict(Task=\"P4\", Start='2018-10-03', Finish='2018-10-12', Resource='P4: Russian Troll Detection'),\n",
    "         dict(Task=\"P5\", Start='2018-10-13', Finish='2018-10-16', Resource='P5: Fall break'),\n",
    "         dict(Task=\"P6\", Start='2018-10-18', Finish='2018-10-21', Resource='P6: Prep CSCW talk - Reddit ban'),\n",
    "         dict(Task=\"P7\", Start='2018-10-10', Finish='2018-10-13', Resource='P7: Prep CSCW talk - Reddit norms'),\n",
    "         dict(Task=\"P8\", Start='2018-11-03', Finish='2018-11-10', Resource='P8: Attend CSCW'),\n",
    "         dict(Task=\"P9\", Start='2018-12-15', Finish='2019-1-15', Resource='P9: ICWSM paper to detect bad actors'),\n",
    "         dict(Task=\"P9\", Start='2018-10-15', Finish='2018-11-15', Resource='P9: ICWSM paper to detect bad actors'),\n",
    "         dict(Task=\"P10\", Start='2018-10-15', Finish='2018-12-10', Resource='P10: Pilot study - New Reddit Automod'),\n",
    "     ]\n",
    "\n",
    "# colors = ['#7a0504', (0.2, 0.7, 0.3), 'rgb(210, 60, 180)']\n",
    "# fig = ff.create_gantt(df, colors=colors, index_col='Resource', reverse_colors=True, show_colorbar=True)\n",
    "\n",
    "fig = ff.create_gantt(df, index_col='Resource', reverse_colors = True, show_colorbar=True)\n",
    "py.iplot(fig, filename='gantt-string-variable', world_readable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
